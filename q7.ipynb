{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "administrative-display",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stunning-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-therapist",
   "metadata": {},
   "source": [
    "Checking the no of samples and shape of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "internal-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "1797\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "X,y = digits.data, digits.target\n",
    "n = X.shape[0]\n",
    "print(n)\n",
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-paragraph",
   "metadata": {},
   "source": [
    "As the pixel values range from 0-15 we should normalize for easier and faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "broad-freeze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.33333333 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.66666667 0.         0.        ]\n",
      " [0.         0.         0.         ... 1.06666667 0.6        0.        ]\n",
      " ...\n",
      " [0.         0.         0.06666667 ... 0.4        0.         0.        ]\n",
      " [0.         0.         0.13333333 ... 0.8        0.         0.        ]\n",
      " [0.         0.         0.66666667 ... 0.8        0.06666667 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "data =np.array(digits.data)\n",
    "data = data/15\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-nigeria",
   "metadata": {},
   "source": [
    "Split data into training and testing (70,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "latter-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64) (540, 64)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-painting",
   "metadata": {},
   "source": [
    "Function to obtain the class conditional probabilities for the Naive Bayes Classifier to perform training and predicition. Sigma will the hyperparameter which we can run a optimiziation for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "demographic-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_scratch(sigma, D_A, D_B):\n",
    "    getcontext().prec = 7\n",
    "    mu, prob_x = D_A.astype(np.float64), 0\n",
    "    len_D_A, len_D_B, d = len(D_A), len(D_B), len(D_A[0])\n",
    "    t_1 = -Decimal(0.5 * d) * Decimal(2 * pi * (sigma ** 2)).ln()\n",
    "    log_k = Decimal(len_D_A).ln()\n",
    "\n",
    "    for i in range(0, len_D_A):\n",
    "        t_0 = np.sum((-((np.matlib.repmat(D_B[i], len_D_A, 1).astype(np.float64) - mu) ** 2)) / (2 * (sigma ** 2)),\n",
    "                     axis=1)\n",
    "        elements_sum = 0\n",
    "        for j in range(0, len_D_B):\n",
    "            elements_sum += Decimal(t_0[j]).exp()\n",
    "        prob_x += t_1 - log_k + elements_sum.ln()\n",
    "    return prob_x / len_D_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-civilian",
   "metadata": {},
   "source": [
    "Class for writing the NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    def calc_prior(self, features, target):\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "\n",
    "        return self.prior\n",
    "    \n",
    "    def calc_statistics(self, features, target):\n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "        return self.mean, self.var\n",
    "    \n",
    "    def gaussian_density(self, class_idx, x):     \n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "    \n",
    "    def RbfKernel(data1, data2, sigma):\n",
    "        delta =abs(np.subtract(data1, data2))\n",
    "        squaredEuclidean = (np.square(delta).sum(axis=1))\n",
    "        result = np.exp(-(squaredEuclidean)/(2*sigma**2))\n",
    "        return result\n",
    "\n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        self.calc_statistics(features, target)\n",
    "        self.calc_prior(features, target)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        preds = [self.Kde_scratch(f) for f in features.to_numpy()]\n",
    "        return preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
